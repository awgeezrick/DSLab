{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finding Magic: The Gathering archetypes with LDA: Code\n",
    "\n",
    "This notebook is meant as a supplement for [this article](https://medium.com/@hlynurd/finding-magic-the-gathering-archetypes-with-latent-dirichlet-allocation-729112d324a6). The results were obtained by working with [this data](Modern.htm). \n",
    "You can try this method on data from other formats as well. There is an API on <a href=\"https://mtgdecks.net\" rel=\"follow\">MTG Decks</a> to access the latest 500 tournament decklists from <a href=\"https://mtgdecks.net/decks/csv/Standard\" rel=\"follow\">Standard</a>, <a href=\"https://mtgdecks.net/decks/csv/Modern\" rel=\"follow\">Modern</a>,\n",
    "<a href=\"https://mtgdecks.net/decks/csv/Legacy\" rel=\"follow\">Legacy</a>, <a href=\"https://mtgdecks.net/decks/csv/Vintage\" rel=\"follow\">Vintage</a>, <a href=\"https://mtgdecks.net/decks/csv/Commander\" rel=\"follow\">Commander</a>, <a href=\"https://mtgdecks.net/decks/csv/Pauper\" rel=\"follow\">Pauper</a>, <a href=\"https://mtgdecks.net/decks/csv/Frontier\" rel=\"follow\">Frontier</a>, <a href=\"https://mtgdecks.net/decks/csv/Peasant\" rel=\"follow\">Peasant</a>  or <a href=\"https://mtgdecks.net/decks/csv/Highlander\" rel=\"follow\">Highlander</a>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing the data\n",
    "\n",
    "The usual first step of machine learning tasks is making sure that the data is in the right form for our algorithms. The raw data is a csv file where each line represents a decklist. Each line contains a main deck and sideboard:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We feed the data into a gensim Dictionary, similarly as in [this tutorial](https://radimrehurek.com/gensim/tut1.html). We split each decklist into individual cards, ignoring the card counts and cards that appear only once. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "import json\n",
    "import re \n",
    "from six import iteritems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with open('validated_decks.json') as f:\n",
    "    j = json.load(f)\n",
    "    card_dictionary = gensim.corpora.Dictionary([card.strip() for card in deck] for deck in j['decks'])\n",
    "    \n",
    "    # remove cards that appear only once\n",
    "    once_ids = [tokenid for tokenid, docfreq in iteritems(card_dictionary.dfs) if docfreq == 1]\n",
    "    card_dictionary.filter_tokens(once_ids)\n",
    "\n",
    "    # remove gaps in id sequence after words that were removed\n",
    "    card_dictionary.compactify()\n",
    "    \n",
    "    unique_cards = len(card_dictionary.keys())\n",
    "    print('unique cards: ', unique_cards)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we create a gensim Corpus. Instead of having a bag of words (cards) model, we take note how many times each card appears in a deck and \"uncompress\" the decklist description."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class MyCorpus(object):\n",
    "    def __iter__(self):\n",
    "        with open('validated_decks.json') as f:\n",
    "            j = json.load(f)\n",
    "            \n",
    "            for deck in j['decks']:\n",
    "                cleaned_decklist = []\n",
    "                for card_name in deck:\n",
    "                    card_count = deck[card_name]\n",
    "                    for i in range(card_count):\n",
    "                        cleaned_decklist.append(card_name)\n",
    "                yield card_dictionary.doc2bow(cleaned_decklist)\n",
    "        \n",
    "corpus_memory_friendly = MyCorpus()  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the model\n",
    "Now that the data is ready, we set the number of achetypes to be found. Setting it to 30 gave me good results. Try varying this and see what happens! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "archetypes = 30"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since there are stochastic steps in the training of the model, you might get slightly different results each time. Having the seed set to 1 allows you to recreate my results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The \"Latent Dirichlet\" part of the method name comes from the assumption that the latent [priors](https://en.wikipedia.org/wiki/Prior_probability) on the per-archetype card distribution and per-decklist archetype distributions are [Dirichlet](https://en.wikipedia.org/wiki/Dirichlet_distribution). This allows us to steer the learning of the model.\n",
    "\n",
    "By incorporating such priors, we can tell the model how we believe the data actually looks like. If we have a large number of archetypes and are confident that each decklist only falls under one archetype, then setting a low alpha indicates that we prefer each decklist to belong to few, dominating archetypes. We can similarly control the archetype-card sparsity with beta. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha_prior = [1.0 / archetypes] * archetypes\n",
    "beta_prior = [1.0 / archetypes] * unique_cards"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We finally train the model. This could take a couple of minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iterations = 30\n",
    "lda = gensim.models.ldamodel.LdaModel(corpus=corpus_memory_friendly, id2word=card_dictionary, num_topics=archetypes, passes=iterations, alpha = alpha_prior, eta = beta_prior)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking the results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Define Functions to convert card IDs to their name and picture**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from PIL import Image\n",
    "import requests\n",
    "from io import BytesIO\n",
    "\n",
    "def getCard(id):\n",
    "    \"\"\"\n",
    "    Returns card JSON based on ID from Scryfall API\n",
    "    \"\"\"\n",
    "    r = requests.get('https://api.scryfall.com/cards/multiverse/' + str(id))\n",
    "    data = r.json()\n",
    "    try:\n",
    "        name = data['name']\n",
    "    except KeyError:\n",
    "        name = ''\n",
    "    try:\n",
    "        url = data['image_uris']['normal']\n",
    "    except KeyError:\n",
    "        url = ''\n",
    "    return name, url\n",
    "\n",
    "def getImage(url):\n",
    "    \"\"\"\n",
    "    Returns \"normal\" image JPEG from Scryfall Image Library\n",
    "    \"\"\"\n",
    "    response = requests.get(url)\n",
    "    img = Image.open(BytesIO(response.content))\n",
    "    return img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A good rule of thumb while doing machine learning work is to do regular sanity checks. Anything from simple output prints to beautiful visualizations will help you understand what's going on. After the training is finished, we can explore the archetypes that it finds. Gensim offers a nice way to see the probability-card pairs in each archetype. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "number_of_top_cards = 16\n",
    "archetypes_to_inspect = 3\n",
    "for i in range(archetypes_to_inspect):\n",
    "    print((\"Archetype %i \\n %s \\n\") % (i, lda.print_topic(i, topn=number_of_top_cards)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Take a look at archetypes**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_archetype_topn(archetype_id, topn, show_name=True):\n",
    "    \"\"\"\n",
    "    Print the top n most probable cards for an archetype.\n",
    "    \n",
    "    This function prints the card name when 'show_name'==True and the\n",
    "    card_id when 'show_name'==False.\n",
    "    \"\"\"\n",
    "    top_cards = np.array(lda.show_topic(archetype_id, topn=topn))\n",
    "    for card in top_cards:\n",
    "        if show_name:\n",
    "            card_name = getCard(card[0])[0]\n",
    "        else:\n",
    "            card_name = card[0]\n",
    "        card_prob = float(card[1])\n",
    "        print('{:.4f} {}'.format(card_prob, card_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "archetype_id = 13\n",
    "topn = 30\n",
    "\n",
    "print_archetype_topn(archetype_id, topn, show_name=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Generate a Deck**\n",
    "\n",
    "Since the model is generative, we can generate new decks as well. Here's an example of how to make a metagame altering affinity deck:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "archetype_id = 10\n",
    "archetype_topic = np.array(lda.show_topic(archetype_id, topn=9999))\n",
    "\n",
    "archetype_distribution = np.array(archetype_topic[:,1], dtype=\"float32\")\n",
    "archetype_distribution = archetype_distribution / np.sum(archetype_distribution)\n",
    "\n",
    "archetype_indices = np.zeros(len(archetype_distribution))\n",
    "main_deck = 60\n",
    "sideboard = 15\n",
    "while np.sum(archetype_indices) < main_deck+sideboard:\n",
    "    new_card = np.random.multinomial(1, archetype_distribution)\n",
    "    archetype_indices += new_card\n",
    "    if 5 in archetype_indices:\n",
    "        archetype_indices -= new_card\n",
    "archetype_cards = np.array(archetype_topic[:,0], dtype=np.unicode_)\n",
    "minimum_cards = 1.0\n",
    "deck_title = 'Archetype: {}'.format(archetype_id)\n",
    "print(deck_title)\n",
    "for i in range(len(archetype_distribution)):\n",
    "    if archetype_indices[i] >= minimum_cards:        \n",
    "        print('%i %s' % (archetype_indices[i], getCard(archetype_cards[i])[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exporting Archetypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_archetypes():\n",
    "    \"\"\"\n",
    "    Export the top most probable cards per archetype to a json file.\n",
    "    \"\"\"\n",
    "    num_archetypes = 30\n",
    "    num_cards = 30\n",
    "    with open('30_archetypes.json', 'w') as f:\n",
    "        archetypes_list = []\n",
    "        for archetype_id in range(num_archetypes):\n",
    "            archetype_json = {}\n",
    "            archetype_json['archetype_id'] = archetype_id\n",
    "            archetype_json['num_cards'] = num_cards\n",
    "            archetype_json['cards'] = []\n",
    "            for card_id, prob in np.array(lda.show_topic(archetype_id, topn=num_cards)):\n",
    "                card_name, image_url = getCard(card_id)\n",
    "                archetype_json['cards'].append({'card_id': card_id,\n",
    "                                                'probability': prob,\n",
    "                                                'card_name': card_name,\n",
    "                                                'image_url': image_url})\n",
    "            archetypes_list.append(archetype_json)\n",
    "        json.dump(archetypes_list, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment the line below to export archetypes\n",
    "export_archetypes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_deck_freq(archetype_num, filename):\n",
    "    \"\"\"\n",
    "    Print out Archetype with name and card images\n",
    "    \"\"\"\n",
    "    with open(filename, 'r') as f:\n",
    "        card_dict = {}\n",
    "        data = json.load(f)\n",
    "        deck = data[archetype_num]\n",
    "        for card in deck['cards']:\n",
    "            name, image_url = getCard(card['card_id'])\n",
    "            if name in card_dict:\n",
    "                card_dict[name] += 1\n",
    "            else:\n",
    "                card_dict[name] = 1\n",
    "        print(card_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_deck_freq(15, '30_archetypes.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Judging Deck Archetypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_deck_archetypes(deck, topn=5):\n",
    "    \"\"\"\n",
    "    Return the top n archetypes of a deck.\n",
    "    \"\"\"\n",
    "    deck_corpus = card_dictionary.doc2bow(deck)\n",
    "    archetype_probs = lda.get_document_topics(deck_corpus)\n",
    "    topn_archetypes = []\n",
    "    for i in range(topn):\n",
    "        highest = (-1, 0)\n",
    "        for archetype_prob in archetype_probs:\n",
    "            if archetype_prob[1] > highest[1]:\n",
    "                highest = archetype_prob\n",
    "        topn_archetypes.append(highest)\n",
    "        archetype_probs.remove(highest)\n",
    "    return topn_archetypes\n",
    "\n",
    "query_deck = []\n",
    "query_deck.append('447176')    # Top card from Archetype 10\n",
    "query_deck.append('447148')    # 2nd top card from Archetype 10\n",
    "print(get_deck_archetypes(query_deck))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
